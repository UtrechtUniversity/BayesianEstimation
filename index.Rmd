---
title: "A gentle introduction to Bayesian Estimation 2025"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: scroll
---

<style>                     
.navbar {
  background-color: #FFCD00;
  border-color: #C00A35;
}
.navbar-brand {
color:black!important;
}


</style>   


# Intro {.sidebar}

This dashboard covers the course materials for the course <a href="https://utrechtsummerschool.nl/courses/data-science/a-gentle-introduction-to-bayesian-estimation" target="_blank">A Gentle Introduction to Bayesian Estimation</a>. 
<br> <br>
We suggest to access the materials online when we consider them. The materials can be downloaded via <a href="https://github.com/UtrechtUniversity/BayesianEstimation" target="_blank">The github page for this course</a>. 

---


Instructors: 

 - <a href="https://www.saravanerp.com/" target="_blank">Sara van Erp</a>
 - <a href="https://suzannehoogeveen.netlify.app" target="_blank">Suzanne Hoogeveen</a>
 - <a href="https://www.uu.nl/staff/FDvanLeeuwen" target="_blank">Florian van Leeuwen</a>
 

---
# Quick Overview

## Column 1

### Outline
This course introduces all the essential ingredients needed to start Bayesian estimation and inference. We discuss specifying priors, obtaining the posterior, prior/posterior predictive checking, sensitivity analyses, and the usefulness of a specific class of priors called shrinkage priors. We propose strategies for reproducibility and reporting standards, outlining the WAMBS-checklist (when to Worry and how to Avoid the Misuse of Bayesian Statistics). We have prepared many exercises to enable students to get hands-on experience.

The popularity of Bayesian statistics has increased over the years; however, Bayesian methods are not a part of the statistics curricula in most graduate programs internationally. The Bayesian framework can handle some commonly encountered problems in classical statistics, such as the lack of power in small sample research and convergence issues in complex models. Furthermore, some researchers prefer the Bayesian framework because it sequentially updates knowledge with new data instead of requiring that each new study tests the null hypothesis that there is no effect in the population. The main focus of the course is on conceptually understanding Bayesian inference and applying Bayesian methods.

The instructors will clarify the differences between the philosophies and interpretations in classical and Bayesian frameworks. They will illustrate how different types of research questions can be answered using Bayesian methods. This course will also give students experience running Bayesian analyses and interpreting results and instruct participants on the prevailing “best practices” for writing a scientific article based on Bayesian statistics. Participants will emerge from the course with knowledge about how to apply Bayesian methods to answer their research questions and with the ability to understand articles that examine and use Bayesian methods.



## Column 2

### Daily schedule 

| When?  |      | What?      |
|:--------|:-------|:-------------|
| 09.00 | 12.00  | Lecture |
|       | <a href="https://www.uu.nl/educatorium" target="_blank">Lunch</a> |            
| 13:00 | 16.00  | Computer lab |


### Lecture Hall locations
| When?  | Where    |
|:--------|:-------|
| Monday | <a href="https://www.uu.nl/en/victor-j-koningsberger-building" target="_blank">Koningsberger - Cosmos</a> |
| Tuesday | <a href="https://www.uu.nl/en/victor-j-koningsberger-building" target="_blank">Koningsberger - Cosmos</a> |
| Wednesday | <a href="https://www.uu.nl/en/victor-j-koningsberger-building" target="_blank">Koningsberger - Cosmos</a> |
| Thursday | <a href="https://www.uu.nl/en/victor-j-koningsberger-building" target="_blank">Koningsberger - Cosmos</a> |
| Friday | <a href="https://www.uu.nl/en/victor-j-koningsberger-building" target="_blank">Koningsberger - Cosmos</a> |

# How to prepare

## Column 1

### Preparing for the course

We have prepared many exercises in `R` and `Python`. If you are not familiar with either `R` or `Python`, we recommend you work with the `R` materials. To get started with `R`, please follow the installation instructions below and work through the exercises before the start of the course. If you are not able to install `R`, you have the possibility to work with the `Python` materials instead via Google Colab. However, not all methods we work with are available in `Python` (yet).  

**1. Install the latest version of `R`**
`R` can be obtained <a href="https://cran.r-project.org" target="_blank">here</a>. We won't use `R` directly in the course, but rather call `R` through `RStudio`. Therefore it needs to be installed. 

**2. Install the latest `RStudio` Desktop**

Rstudio is an Integrated Development Environment (IDE). It can be obtained as stand-alone software <a href="https://posit.co/download/rstudio-desktop/#download" target="_blank">here</a>. The free and open source `RStudio Desktop` version is sufficient.

**3. Make sure you have a C++ compiler**

We will use several packages, but mostly `brms` in `R`. As explained <a href="https://cran.r-project.org/web/packages/brms/readme/README.html" target="_blank">here</a>: *Because brms is based on Stan, a C++ compiler is required. The program* `Rtools` *(available* <a href="https://cran.r-project.org/bin/windows/Rtools/" target="_blank">here</a> *comes with a C++ compiler for Windows. On Mac, you should install* `Xcode`. *For further instructions on how to get the compilers running, see the prerequisites section * <a href="https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started" target="_blank">here</a>. 

### Materials

**Exercise ‘Intro R’**

If you're not familiar with `R`, you might want to work on these two exercises first before continuing:

The first is a basic intro to `R`. By following the steps outlined in this tutorial, you will establish a fundamental understanding of `R`. For this exercise click <a href="content/how to prepare/R_for_beginners_version1.html" target="_blank">here</a>.

The second exercise guides you through frequentist regression analysis in R, building upon your foundational knowledge. For this exercise, click <a href="content/how to prepare/R_regression_frequentist.html" target="_blank">here</a>.

The underlying code is available on <a href="https://github.com/Rensvandeschoot/Tutorials" target="_blank">GitHub</a>. Your feedback (via an issue or PR) to the code or the exercises is very much appreciated!



## Column 2

### Useful references

https://cran.r-project.org

https://posit.co/download/rstudio-desktop/#download

https://cran.r-project.org/bin/windows/Rtools/

https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started

https://www.rensvandeschoot.com/tutorials/r-for-beginners/ 

https://www.rensvandeschoot.com/tutorials/linear-regression-in-r-frequentist/ 

https://github.com/Rensvandeschoot/Tutorials

https://www.python.org

https://colab.google



# Monday

## Column 1


### Outline
Day 1: we discuss the stages involved in Bayesian analysis: obtaining background knowledge from previous literature, specifying the prior distributions,  and deriving the posterior. We discuss the importance of prior and posterior predictive checking, and selecting a proper technique for sampling from a probability distribution. We prepared exercises in web apps to play around with priors and data to learn how these will affect the posterior.


### Materials
We adapt the course as we go. To ensure that you work with the latest iteration of the course materials, we advice all course participants to access the materials online.

- <a href="content/monday/slides_day1.pdf" target="_blank">Slides day 1</a>

**Exercise ‘First Bayesian Inference'**

The first exercise makes use of a Shiny App that is designed to ease its users’ first contact with Bayesian statistical inference. By "pointing and clicking", the user can analyze the IQ example which has been used in the gentle introduction to Bayesian inference in van de Schoot et al. (2014).

For the exercise click <a href="content/monday/First-Bayesian-Inference-Exercise.html" target="_blank">here</a>.
To get to the Shiny App click <a href="https://utrecht-university.shinyapps.io/bayesian_estimation/" target="_blank">here</a>.

The underlying code is available on <a href="https://github.com/Rensvandeschoot/First-Bayesian-Inference" target="_blank">GitHub</a>. If you like the App, leave a star. Feedback (via an issue or PR) to the code or the exercise is very much appreciated!

**Exercise ‘Plausible Parameter Space’**

The Plausible Parameter Space (PPS) Shiny App is designed to help users define their priors in a linear regression with two regression coefficients. Users are asked to specify their plausible parameter space and their expected prior means and uncertainty around these means. The PhD-delay data is used as an easy-to-go introduction 

For the exercise click <a href="https://utrecht-university.shinyapps.io/priors_phd/" target="_blank">here</a>. 

The underlying code is available on <a href="https://github.com/Rensvandeschoot/Plausible-Parameter-Space" target="_blank">GitHub</a>. If you like the App, leave a star. Feedback (via an issue or PR) to the code or the exercise is very much appreciated!


## Column 2

### Useful references

van de Schoot, R., Depaoli, S., King, R. et al. Bayesian statistics and modelling. Nature Review Methods Primers 1, 1 (2021). https://doi.org/10.1038/s43586-020-00001-2 

van de Schoot, R., Kaplan, D., Denissen, J., Asendorpf, J. B., Neyer, F. J. and van Aken, M. A.G. (2014), A Gentle Introduction to Bayesian Analysis: Applications to Developmental Research. Child Dev, 85: 842–860. https://doi.org/10.1111/cdev.12169

https://www.rensvandeschoot.com/tutorials/fbi/

https://github.com/Rensvandeschoot/First-Bayesian-Inference 

https://www.rensvandeschoot.com/pps

https://github.com/Rensvandeschoot/Plausible-Parameter-Space 

# Tuesday

## Column 1

### Outline
Day 2: we discuss reproducibility and reporting standards strategies, outlining the WAMBS-checklist (when to Worry and how to Avoid the Misuse of Bayesian Statistics).  We have prepared exercises in R (`brms`) and Python (`bambi`) to get hands-on experience. 

### Materials
We adapt the course as we go. To ensure that you work with the latest iteration of the course materials, we advice all course participants to access the materials online.

- <a href="content/tuesday/slides_day2.pdf" target="_blank">Slides day 2</a>

The exercises are available in R and Python, so you can choose the program you are most familiar with. Note that, if you work in R, the exercise requires a working version of the `brms` packages. See the `How to prepare` page if you do not have this yet. If you work in Python, we advise you to download the Jupyter notebooks and open them in [Google colab](https://colab.google) to work on the practical.

The first exercise goes through the When-to-Worry-and-How-to-Avoid-the-Misuse-of-Bayesian-Statistics (WAMBS) – checklist for a simple regression model. Then follows a 3 part series on how to run multilevel models. In part 1 we explain how to build a multilevel model. In part 2 we will look at the influence of different priors and in part 3 we will go through the WAMBS checklist again. 

**Exercise ‘WAMBS'**

This exercise leverages the power of the `brms` package in R or the `bambi` package in Python to help users create Bayesian models and check them using the WAMBS – checklist. 

For the exercise in R, click <a href="content/tuesday/Wambs_R_using_brms.html" target="_blank">here</a>.

For the practical in Python, please download <a href="content/tuesday/WAMBS_Python_full.ipynb" download>this Jupyter notebook</a>

- [data file phd-delays](content/tuesday/phd-delays.csv)


**Exercise 'Building a Multilevel Model'**

In this exercise you go through the process of building a multilevel model. It is a practical and hands-on approach aimed at making Bayesian multilevel modeling accessible for both beginners and those with some experience. 

For the exercise in R, click <a href="content/tuesday/Tutorial_BRMS.html" target="_blank">here</a>.


**Exercise ‘Influence of Priors'**

This exercise is designed to make Bayesian inference more accessible for beginners. Just as in the earlier tutorial, users can engage with real-world examples to better understand the principles of Bayesian analysis.

For the exercise in R, click <a href="content/tuesday/Priors_BRMS.html" target="_blank">here</a>. 

**Exercise 'Multilevel WAMBS'**

In this tutorial you will be following the steps of the WAMBS – checklist to analyze the cross level interaction model we did in the 'Building a Multilevel Model' exercise 

For the exercise in R, click <a href="content/tuesday/WAMBS_multilevel.html" target="_blank">here</a>.


## Column 2

### Useful references

Depaoli, S., & Van de Schoot, R. (2017). Improving transparency and replication in Bayesian statistics: The WAMBS-Checklist. Psychological methods, 22(2), 240.

Van de Schoot, R., Veen, D., Smeets, L., Winter, S. D., & Depaoli, S. (2020). A tutorial on using the WAMBS checklist to avoid the misuse of Bayesian statistics. Small Sample Size Solutions: A Guide for Applied Researchers and Practitioners; van de Schoot, R., Miocevic, M., Eds, 30-49.

https://github.com/UtrechtUniversity/BayesianEstimation



# Wednesday

## Column 1

### Outline
Day 3: we discuss estimation methods including alternatives that can be more efficient when dealing with computational or non-covergence issues. A brief introduction to and  the benefits of these estimation methods (MCMC, Gibbs, MH, HMC, NUTS, etc.) will be reviewed. These insights can help to understand differences between software that can be used. Additionally, we will go into prior and posterior predictive checking. These are great tools to help understand what your models and priors are implying. Today may be a little more technical (less gentle) but without equations.

### Materials
We adapt the course as we go. To ensure that you work with the latest iteration of the course materials, we advice all course participants to access the materials online. 

- <a href="content/wednesday/slides_day3.pdf" target="_blank">Slides day 3</a>

The exercises are available in R and Python, so you can choose the program you are most familiar with. Note that, if you work in R, the exercise requires a working version of the `brms` packages. See the `How to prepare` page if you do not have this yet. If you work in Python, we advise you to download the Jupyter notebooks and open them in [Google colab](https://colab.google) to work on the practical.

**Practical 'Predictive checking'**

This practical goes through the steps to perform prior and posterior predictive checks using `brms` (in R) or `bambi` (in Python). A case study shows the importance of tailoring predictive checks to the application at hand. 

For the practical in R, click <a href="content/wednesday/prior_posterior_predictive_practical.html" target="_blank">here</a>.

For the practical in Python, please download <a href="content/wednesday/prior_posterior_predictive_practical_python.ipynb" download>this Jupyter notebook</a>.

- [data file time_data](content/wednesday/time_data.csv)

**Additional material 'MCMC convergence and checks'**

<a href="content/wednesday/convergence_checks.html" target="_blank">This file</a> contains some more information on MCMC convergence diagnostics available in `brms` and runs through the custom posterior predictive check discussed during the lecture.

**Additional material 'non-MCMC methods'**

<a href="content/wednesday/Non-MCMC_methods" target="_blank">This file</a> illustrates how to run different approximate algorithms available in `Stan`.

## Column 2

### Useful references


https://chi-feng.github.io/mcmc-demo/

Blei, D. M., Kucukelbir, A., & McAuliffe, J. D. (2017). Variational inference: A review for statisticians. Journal of the American statistical Association, 112(518), 859-877.

Jonah Gabry, Daniel Simpson, Aki Vehtari, Michael Betancourt, Andrew Gelman, Visualization in Bayesian Workflow, Journal of the Royal Statistical Society Series A: Statistics in Society, Volume 182, Issue 2, February 2019, Pages 389–402, https://doi.org/10.1111/rssa.12378

Monnahan, C. C., Thorson, J. T., & Branch, T. A. (2017). Faster estimation of Bayesian models in ecology using Hamiltonian Monte Carlo. Methods in Ecology and Evolution, 8(3), 339-348.

https://github.com/UtrechtUniversity/BayesianEstimation

# Thursday

## Column 1


### Outline
Day 4: although the prior distribution can offer many advantages, the prior can also inadvertently influence the results. Today we will discuss the importance of prior sensitivity analysis to investigate the influence the prior has on the results. We will focus on models with many parameters to estimate, possibly too many for the model to be identified in a classical sense. We discuss the use of shrinkage priors to estimate these models and select substantial parameters.

### Materials
We adapt the course as we go. To ensure that you work with the latest iteration of the course materials, we advice all course participants to access the materials online.

- <a href="content/thursday/slides_day4.pdf" target="_blank">Slides day 4</a>

The exercises are available in R and Python, so you can choose the program you are most familiar with. Note that, if you work in R, the exercise requires a working version of the `brms` packages. See the `How to prepare` page if you do not have this yet. If you work in Python, we advise you to download the Jupyter notebooks and open them in [Google colab](https://colab.google) to work on the practical.

**Practical 'Bayesian regularized regression'**

This practical goes through the steps to perform a Bayesian regularized regression with `brms` (in R) or `bambi` (in Python) to predict the age of abalone. Note that there are some differences in the R and Python exercises due to the implementation of different shrinkage priors in `brms` and `bambi`. In addition, projection predictive variable selection is not (yet) available for use with `bambi`.

For the practical in R, click <a href="content/thursday/exercises_Bayesian_regularization.html" target="_blank">here</a>.

For the practical in Python, please download <a href="content/thursday/exercise_Bayesian_regularization_python.ipynb" target="_blank">this Jupyter notebook</a>.

- [abalone.data](content/thursday/abalone.data) This data is shared by Nash, Warwick, Sellers, Tracy, Talbot, Simon, Cawthorn, Andrew, and Ford, Wes. (1995). Abalone. UCI Machine Learning Repository. https://doi.org/10.24432/C55C7W. 

## Column 2

### Useful references

van Erp, S., Oberski, D. L., & Mulder, J. (2019). Shrinkage Priors for Bayesian Penalized Regression. Journal of Mathematical Psychology, 89, 31-50. [doi:10.1016/j.jmp.2018.12.004](https://www.sciencedirect.com/science/article/abs/pii/S0022249618300567).

van Erp, S. (2020). [A tutorial on Bayesian penalized regression with shrinkage priors for small sample sizes](https://library.oapen.org/bitstream/handle/20.500.12657/22385/9780367221898_text%20(1).pdf?sequence=1#page=85). Small sample size solutions, 71-84. 

https://github.com/UtrechtUniversity/BayesianEstimation

# Friday

## Column 1

### Outline
Day 5: today we quickly summarize what we've learned about (informative) priors. Then we look at *simulation-based calibration* as a method to assess the computational faithfulness of our model; do all three key elements of Bayesian estimation (prior, likelihood, and posterior) collaborate as expected? Upon request, we also quickly provide a sneak-peak into hypothesis testing with Bayes factors: what, why and how could we apply it in the Bayesian workflow? In the afternoon, there will be opportunity to analyse your own data using the techniques learned during the week. 

### Materials
We adapt the course as we go. To ensure that you work with the latest iteration of the course materials, we advice all course participants to access the materials online.

- <a href="content/friday/slides_day5.pdf" target="_blank">Slides day 5</a>

There are two tutorials/vignettes available today. However, to preserve time for the 'do-it-yourself' exercise, we'd recommend you only pick one and keep the other for later. 

**Practical ‘Simulation-Based Calibration'**

In this tutorial, you'll walk through the steps of a robust Bayesian workflow, including prior predictive checks, assessing computational faithfulness and sensitivity through simulation-based calibration, and posterior predictive checks. Note that the practicals are only available in R. 

For the practical in R, click <a href="content/friday/SBC.html" target="_blank">here</a>.

**Practical ‘Hypothesis testing with Bayes factors'**

In this tutorial, you'll learn how to perform hypothesis testing using Bayes factors using the Savage-Dickey density ratio method and model comparison with bridgesampling. This practical is only available in R.

For the practical in R, click <a href="content/friday/Bayes_factors.html" target="_blank">here</a>.

- [data file afterlife_beliefs](content/friday/afterlife_beliefs.csv)

**Exercise ‘Skills showcase'**

In this exercise, you will analyse your own data to showcase the skills you have learned during the week. You can find the exercise - <a href="content/friday/skills_showcase.html" target="_blank">here</a>.

Please note: if you are participating in this course via IOPS, please email your Markdown document before August 25, 2025 to obtain your credits.

## Column 2

### Useful references

Heck, D. W., Boehm, U., Böing-Messing, F., Bürkner, P.-C., Derks, K., Dienes, Z., Fu, Q., Gu, X., Karimova, D., Kiers, H. A. L., Klugkist, I., Kuiper, R. M., Lee, M. D., Leenders, R., Leplaa, H. J., Linde, M., Ly, A., Meijerink-Bosman, M., Moerbeek, M., … Hoijtink, H. (2023). A review of applications of the Bayes factor in psychological research. Psychological Methods, 28(3), 558–579. https://doi.org/10.1037/met0000454

Schad, D. J., Betancourt, M., & Vasishth, S. (2021). Toward a principled Bayesian workflow in cognitive science. Psychological Methods, 26(1), 103–126. https://doi.org/10.1037/met0000275

Talts, S., Betancourt, M., Simpson, D., Vehtari, A., & Gelman, A. (2018). Validating Bayesian Inference Algorithms with Simulation-Based Calibration (No. arXiv:1804.06788). arXiv. https://doi.org/10.48550/arXiv.1804.06788

Veen, D., Stoel, D., Zondervan-Zwijnenburg, M., & Van de Schoot, R. (2017). Proposal for a five-step method to elicit expert judgment. Frontiers in psychology, 8, 2110. https://doi.org/10.3389/fpsyg.2017.02110.

https://utrecht-university.shinyapps.io/elicitation/

https://github.com/VeenDuco/Five-Step-Method-Shinyapp

