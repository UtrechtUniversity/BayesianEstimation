@misc{gelman2020bayesian,
  title = {Bayesian {{Workflow}}},
  author = {Gelman, Andrew and Vehtari, Aki and Simpson, Daniel and Margossian, Charles C. and Carpenter, Bob and Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and B{\"u}rkner, Paul-Christian and Modr{\'a}k, Martin},
  year = {2020},
  month = nov,
  number = {arXiv:2011.01808},
  eprint = {2011.01808},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2011.01808},
  urldate = {2025-07-24},
  abstract = {The Bayesian approach to data analysis provides a powerful way to handle uncertainty in all observations, model parameters, and model structure using probability theory. Probabilistic programming languages make it easier to specify and fit Bayesian models, but this still leaves us with many options regarding constructing, evaluating, and using these models, along with many remaining challenges in computation. Using Bayesian inference to solve real-world problems requires not only statistical skills, subject matter knowledge, and programming, but also awareness of the decisions made in the process of data analysis. All of these aspects can be understood as part of a tangled workflow of applied Bayesian statistics. Beyond inference, the workflow also includes iterative model building, model checking, validation and troubleshooting of computational problems, model understanding, and model comparison. We review all these aspects of workflow in the context of several examples, keeping in mind that in practice we will be fitting many models for any given problem, even if only a subset of them will ultimately be relevant for our conclusions.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Methodology},
  file = {/Users/3659690/Zotero/storage/DFQSNZ65/Gelman et al. - 2020 - Bayesian Workflow.pdf;/Users/3659690/Zotero/storage/MTWWPNY6/2011.html}
}

@article{gronau2020bridgesampling,
  title = {Bridgesampling: {{An R Package}} for {{Estimating Normalizing Constants}}},
  author = {Gronau, Q. F. and Singmann, H. and Wagenmakers, E.-J.},
  year = {2020},
  journal = {Journal of Statistical Software},
  volume = {92},
  keywords = {dissertation}
}

@article{heck2023review,
  title = {A Review of Applications of the {{Bayes}} Factor in Psychological Research.},
  author = {Heck, Daniel W. and Boehm, Udo and {B{\"o}ing-Messing}, Florian and B{\"u}rkner, Paul-Christian and Derks, Koen and Dienes, Zoltan and Fu, Qianrao and Gu, Xin and Karimova, Diana and Kiers, Henk A. L. and Klugkist, Irene and Kuiper, Rebecca M. and Lee, Michael D. and Leenders, Roger and Leplaa, Hidde J. and Linde, Maximilian and Ly, Alexander and {Meijerink-Bosman}, Marlyne and Moerbeek, Mirjam and Mulder, Joris and Palfi, Bence and Sch{\"o}nbrodt, Felix D. and Tendeiro, Jorge N. and Van Den Bergh, Don and Van Lissa, Caspar J. and Van Ravenzwaaij, Don and Vanpaemel, Wolf and Wagenmakers, Eric-Jan and Williams, Donald R. and {Zondervan-Zwijnenburg}, Mari{\"e}lle and Hoijtink, Herbert},
  year = {2023},
  month = jun,
  journal = {Psychological Methods},
  volume = {28},
  number = {3},
  pages = {558--579},
  publisher = {American Psychological Association (APA)},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000454},
  urldate = {2025-07-24},
  abstract = {The last 25 years have shown a steady increase in attention for the Bayes factor as a tool for hypothesis evaluation and model selection. The present review highlights the potential of the Bayes factor in psychological research. We discuss six types of applications: Bayesian evaluation of point null, interval, and informative hypotheses, Bayesian evidence synthesis, Bayesian variable selection and model averaging, and Bayesian evaluation of cognitive models. We elaborate what each application entails, give illustrative examples, and provide an overview of key references and software with links to other applications. The paper is concluded with a discussion of the opportunities and pitfalls of Bayes factor applications and a sketch of corresponding future research lines.},
  langid = {english},
  file = {/Users/3659690/Zotero/storage/686YKDCJ/Heck et al. - 2023 - A review of applications of the Bayes factor in psychological research..pdf}
}

@article{hoijtink2019tutorial,
  title = {A Tutorial on Testing Hypotheses Using the {{Bayes}} Factor},
  author = {Hoijtink, Herbert and Mulder, Joris and {van Lissa}, Caspar and Gu, Xin},
  year = {2019},
  journal = {Psychological Methods},
  volume = {24},
  number = {5},
  pages = {539--556},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1463},
  doi = {10.1037/met0000201},
  abstract = {Learning about hypothesis evaluation using the Bayes factor could enhance psychological research. In contrast to null-hypothesis significance testing it renders the evidence in favor of each of the hypotheses under consideration (it can be used to quantify support for the null-hypothesis) instead of a dichotomous reject/do-not-reject decision; it can straightforwardly be used for the evaluation of multiple hypotheses without having to bother about the proper manner to account for multiple testing; and it allows continuous reevaluation of hypotheses after additional data have been collected (Bayesian updating). This tutorial addresses researchers considering to evaluate their hypotheses by means of the Bayes factor. The focus is completely applied and each topic discussed is illustrated using Bayes factors for the evaluation of hypotheses in the context of an ANOVA model, obtained using the R package bain. Readers can execute all the analyses presented while reading this tutorial if they download bain and the R-codes used. It will be elaborated in a completely nontechnical manner: what the Bayes factor is, how it can be obtained, how Bayes factors should be interpreted, and what can be done with Bayes factors. After reading this tutorial and executing the associated code, researchers will be able to use their own data for the evaluation of hypotheses by means of the Bayes factor, not only in the context of ANOVA models, but also in the context of other statistical models. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Analysis of Variance,Errors,Hypothesis Testing,Null Hypothesis Testing,Statistical Probability,Statistical Significance},
  file = {/Users/3659690/Zotero/storage/W9PR2MYQ/Hoijtink et al. - 2019 - A tutorial on testing hypotheses using the Bayes f.pdf;/Users/3659690/Zotero/storage/TXPDLDFZ/2019-07157-001.html}
}

@misc{hoogeveen2023does,
  title = {Does She Still Love and Feel Hungry? {{Afterlife}} Beliefs, Mind-Body Dualism, and Religion across 24 Countries},
  author = {Hoogeveen, Suzanne and Altay, Sacha and Bendixen, Theiss and Berni{\=u}nas, Renatas and Bulbulia, Joseph A and Cheshin, Arik and Gentili, Claudio and Georgescu, Raluca and Haaf, Julia M. and Hagel, Kristin and Kavanagh, Christopher M. and Levy, Neil and McKay, Ryan and Neely, Alejandra and Qiu, Lin and Rabelo, Andr{\'e} and Ramsay, Jonathan E. and Ross, Robert M. and Turpin, Hugh and Wuyts, Robin and Xygalatas, Dimitris and {van Elk}, Michiel},
  year = {2023},
  publisher = {PsyArXiv},
  doi = {10.31234/osf.io/tvycp},
  author+an = {1=highlight, 1=first, 2=first},
  status = {submitted},
  keywords = {dissertation},
  file = {/Users/3659690/Zotero/storage/FE8AR65A/Hoogeveen et al. - 2023 - Does she still love and feel hungry Afterlife bel.pdf}
}

@article{kucharsky2021hidden,
  title = {Hidden {{Markov Models}} of {{Evidence Accumulation}} in {{Speeded Decision Tasks}}},
  author = {Kucharsk{\'y}, {\v S}imon and Tran, N.-Han and Veldkamp, Karel and Raijmakers, Maartje and Visser, Ingmar},
  year = {2021},
  month = dec,
  journal = {Computational Brain \& Behavior},
  volume = {4},
  number = {4},
  pages = {416--441},
  issn = {2522-087X},
  doi = {10.1007/s42113-021-00115-0},
  urldate = {2023-10-03},
  abstract = {Speeded decision tasks are usually modeled within the evidence accumulation framework, enabling inferences on latent cognitive parameters, and capturing dependencies between the observed response times and accuracy. An example is the speed-accuracy trade-off, where people sacrifice speed for accuracy (or vice versa). Different views on this phenomenon lead to the idea that participants may not be able to control this trade-off on a continuum, but rather switch between distinct states (Dutilh et al., Cognitive Science 35(2):211--250, 2010). Hidden Markov models are used to account for switching between distinct states. However, combining evidence accumulation models with a hidden Markov structure is a challenging problem, as evidence accumulation models typically come with identification and computational issues that make them challenging on their own. Thus, an integration of hidden Markov models with evidence accumulation models has still remained elusive, even though such models would allow researchers to capture potential dependencies between response times and accuracy within the states, while concomitantly capturing different behavioral modes during cognitive processing. This article presents a model that uses an evidence accumulation model as part of a hidden Markov structure. This model is considered as a proof of principle that evidence accumulation models can be combined with Markov switching models. As such, the article considers a very simple case of a simplified Linear Ballistic Accumulation. An extensive simulation study was conducted to validate the model's implementation according to principles of robust Bayesian workflow. Example reanalysis of data from Dutilh et al. (Cognitive Science 35(2):211--250, 2010) demonstrates the application of the new model. The article concludes with limitations and future extensions or alternatives to the model and its application.},
  langid = {english},
  keywords = {Evidence accumulation,Hidden Markov models,Phase transition,Response times,Speed-accuracy trade-off,Speeded decision},
  file = {/Users/3659690/Zotero/storage/IE2W3KRA/Kucharský et al. - 2021 - Hidden Markov Models of Evidence Accumulation in S.pdf}
}

@article{schad2021principled,
  title = {Toward a Principled {{Bayesian}} Workflow in Cognitive Science},
  author = {Schad, Daniel J. and Betancourt, Michael and Vasishth, Shravan},
  year = {2021},
  journal = {Psychological Methods},
  volume = {26},
  number = {1},
  pages = {103--126},
  issn = {1939-1463},
  doi = {10.1037/met0000275},
  abstract = {Experiments in research on memory, language, and in other areas of cognitive science are increasingly being analyzed using Bayesian methods. This has been facilitated by the development of probabilistic programming languages such as Stan, and easily accessible front-end packages such as brms. The utility of Bayesian methods, however, ultimately depends on the relevance of the Bayesian model, in particular whether or not it accurately captures the structure of the data and the data analyst's domain expertise. Even with powerful software, the analyst is responsible for verifying the utility of their model. To demonstrate this point, we introduce a principled Bayesian workflow (Betancourt, 2018) to cognitive science. Using a concrete working example, we describe basic questions one should ask about the model: prior predictive checks, computational faithfulness, model sensitivity, and posterior predictive checks. The running example for demonstrating the workflow is data on reading times with a linguistic manipulation of object versus subject relative clause sentences. This principled Bayesian workflow also demonstrates how to use domain knowledge to inform prior distributions. It provides guidelines and checks for valid data analysis, avoiding overfitting complex models to noise, and capturing relevant data structure in a probabilistic model. Given the increasing use of Bayesian methods, we aim to discuss how these methods can be properly employed to obtain robust answers to scientific questions. All data and code accompanying this article are available from https://osf.io/b2vx9/. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Bayesian Analysis,Cognitive Science,Computer Programming Languages,Experience Level,Flow (Consciousness State),Memory,Prediction,Probability},
  file = {/Users/3659690/Zotero/storage/6BNXSH2T/Schad et al. - 2021 - Toward a principled Bayesian workflow in cognitive.pdf;/Users/3659690/Zotero/storage/Z6RBBTZF/2020-43606-001.html}
}

@misc{talts2018validating,
  title = {Validating {{Bayesian Inference Algorithms}} with {{Simulation-Based Calibration}}},
  author = {Talts, Sean and Betancourt, Michael and Simpson, Daniel and Vehtari, Aki and Gelman, Andrew},
  year = {2018},
  number = {arXiv:1804.06788},
  eprint = {1804.06788},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1804.06788},
  urldate = {2023-10-03},
  abstract = {Verifying the correctness of Bayesian computation is challenging. This is especially true for complex models that are common in practice, as these require sophisticated model implementations and algorithms. In this paper we introduce {\textbackslash}emph\{simulation-based calibration\} (SBC), a general procedure for validating inferences from Bayesian algorithms capable of generating posterior samples. This procedure not only identifies inaccurate computation and inconsistencies in model implementations but also provides graphical summaries that can indicate the nature of the problems that arise. We argue that SBC is a critical part of a robust Bayesian workflow, as well as being a useful tool for those developing computational algorithms and statistical software.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Methodology},
  file = {/Users/3659690/Zotero/storage/KGLMJNQF/Talts et al. - 2020 - Validating Bayesian Inference Algorithms with Simu.pdf;/Users/3659690/Zotero/storage/Y92WYU97/1804.html}
}
